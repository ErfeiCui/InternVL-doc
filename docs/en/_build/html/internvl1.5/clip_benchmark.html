

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>InternVL for Zero-Shot Image Classification &amp; Image-Text Retrieval &#8212; internvl</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/readthedocs.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'internvl1.5/clip_benchmark';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 25, 2024"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/internvl-logo.svg" class="logo__image only-light" alt="internvl - Home"/>
    <script>document.write(`<img src="../_static/internvl-logo.svg" class="logo__image only-dark" alt="internvl - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/eval_data_preparation.html">Eval Data Preparation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">InternVL 1.1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internvl1.1/internvl_chat.html">internvl_chat</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">InternVL 1.0</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/clip_benchmark.html">clip_benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/segmentation.html">segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/internvl_chat_llava.html">internvl_chat_llava</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/internvl_g.html">internvl_g</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL/blob/main/docs/en/internvl1.5/clip_benchmark.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL/edit/main/docs/en/internvl1.5/clip_benchmark.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL/issues/new?title=Issue%20on%20page%20%2Finternvl1.5/clip_benchmark.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/internvl1.5/clip_benchmark.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>InternVL for Zero-Shot Image Classification & Image-Text Retrieval</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installation">Installation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-preparation">Model Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-zero-shot-image-classification">Evaluation: Zero-Shot Image Classification</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#imagenet-variants-and-objectnet">ImageNet variants and ObjectNet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multilingual-imagenet-1k">Multilingual ImageNet-1K</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-datasets">Other Datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-zero-shot-image-text-retrieval">Evaluation: Zero-Shot Image-Text Retrieval</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#flickr30k-coco">Flickr30K &amp; COCO</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#flickr30k-cn-coco-cn">Flickr30K-CN &amp; COCO-CN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xtd">XTD</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#original-readme-of-clip-benchmark">Original README of CLIP Benchmark</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#features">Features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-install">How to install?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use">How to use?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#command-line-interface-cli">Command line interface (CLI)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-other-models-than-openclip">Using other models than openclip</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-add-other-clip-models">How to add other CLIP models</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cifar-10-example">CIFAR-10 example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#voc2007-example">VOC2007 example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vtab-example">VTAB example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-dataset-example">TensorFlow dataset example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coco-captions-example">COCO captions example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#webdataset-example">Webdataset example</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-webdataset">Creating a webdataset</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-on-a-webdataset">Evaluating on a webdataset</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-mulitple-models-on-multiple-datasets">Evaluate mulitple models on multiple datasets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pretrained-models-and-datasets-list-as-arguments">Pretrained models and datasets list as arguments</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pretrained-models-and-datasets-list-as-files">Pretrained models and datasets list as files</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-and-dataset-collections">Model and dataset collections</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#development">Development</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credits">Credits</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="internvl-for-zero-shot-image-classification-image-text-retrieval">
<h1>InternVL for Zero-Shot Image Classification &amp; Image-Text Retrieval<a class="headerlink" href="#internvl-for-zero-shot-image-classification-image-text-retrieval" title="Permalink to this heading">#</a></h1>
<p>This folder contains the implementation of InternVL for zero-shot image classification and zero-shot image-text retrieval, which corresponds to Section 4.3 of our <a class="reference external" href="https://arxiv.org/pdf/2312.14238">InternVL 1.0 paper</a>.
We mainly use <a class="reference external" href="https://github.com/LAION-AI/CLIP_benchmark">CLIP Benchmark</a> to evaluate the performance of InternVL. Thanks for this great work.</p>
<p>In this part, we evaluate the inherent capabilities of InternVL 1.0 on various vision-language tasks.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading">#</a></h2>
<p>First, follow the <a class="reference internal" href="../get_started/installation.html"><span class="std std-doc">installation guide</span></a> to perform some basic installations.</p>
<p>In addition, using this codebase requires executing the following steps:</p>
<ul>
<li><p>Install other requirements:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</li>
<li><p>Install <code class="docutils literal notranslate"><span class="pre">clip_benchmark</span></code> using development mode:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>setup.py<span class="w"> </span>develop
<span class="c1"># You can also add the current directory to PYTHONPATH instead.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">PYTHONPATH</span><span class="si">}</span><span class="s2">:</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this heading">#</a></h2>
<p>This codebase will automatically download the required dataset. If the dataset fails to download automatically, please refer to this <a class="reference internal" href="#./clip_benchmark/datasets/builder.py"><span class="xref myst">file</span></a> for manual downloading.</p>
</section>
<section id="model-preparation">
<h2>Model Preparation<a class="headerlink" href="#model-preparation" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model name</p></th>
<th class="head text-center"><p>type</p></th>
<th class="head"><p>download</p></th>
<th class="head text-center"><p>size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>InternVL-C-13B-224px</p></td>
<td class="text-center"><p>pytorch</p></td>
<td><p>🤗 <a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL/blob/main/internvl_c_13b_224px.pth">HF link</a></p></td>
<td class="text-center"><p>25.4 GB</p></td>
</tr>
<tr class="row-odd"><td><p>InternVL-14B-224px</p></td>
<td class="text-center"><p>huggingface</p></td>
<td><p>🤗 <a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-14B-224px">HF link</a></p></td>
<td class="text-center"><p>27.7 GB</p></td>
</tr>
</tbody>
</table>
<p>Please download the above model weights and place them in the <code class="docutils literal notranslate"><span class="pre">pretrained/</span></code> folder.</p>
<p>You can download either the PyTorch version or the Hugging Face version based on your needs.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>pretrained/
wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/resolve/main/internvl_c_13b_224px.pth
<span class="c1"># pip install -U huggingface_hub</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--resume-download<span class="w"> </span>--local-dir-use-symlinks<span class="w"> </span>False<span class="w"> </span>OpenGVLab/InternVL-14B-224px<span class="w"> </span>--local-dir<span class="w"> </span>internvl_14b_224px
</pre></div>
</div>
<p>The directory structure is:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pretrained
├──<span class="w"> </span>internvl_c_13b_224px.pth
└──<span class="w"> </span>internvl_14b_224px/
</pre></div>
</div>
</section>
<section id="evaluation-zero-shot-image-classification">
<h2>Evaluation: Zero-Shot Image Classification<a class="headerlink" href="#evaluation-zero-shot-image-classification" title="Permalink to this heading">#</a></h2>
<section id="imagenet-variants-and-objectnet">
<h3>ImageNet variants and ObjectNet<a class="headerlink" href="#imagenet-variants-and-objectnet" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>model name</p></th>
<th class="head text-center"><p>IN-1K</p></th>
<th class="head text-center"><p>IN-A</p></th>
<th class="head text-center"><p>IN-R</p></th>
<th class="head text-center"><p>IN-V2</p></th>
<th class="head text-center"><p>IN-Sketch</p></th>
<th class="head text-center"><p>ObjectNet</p></th>
<th class="head text-center"><p>∆</p></th>
<th class="head text-center"><p>average</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>InternVL-C</p></td>
<td class="text-center"><p>83.2</p></td>
<td class="text-center"><p>83.8</p></td>
<td class="text-center"><p>95.5</p></td>
<td class="text-center"><p>77.3</p></td>
<td class="text-center"><p>73.9</p></td>
<td class="text-center"><p>80.6</p></td>
<td class="text-center"><p>0.8</p></td>
<td class="text-center"><p>82.4</p></td>
</tr>
</tbody>
</table>
<details>
  <summary>[InternVL-C] ImageNet-1K val</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet1k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-1k/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet1k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.83178</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.97322</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.83204</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-A</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet-a&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-a/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet-a&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.8377333333333333</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9558666666666666</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.8183934468491632</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-R</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet-r&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-r/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet-r&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9549666666666666</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9918333333333333</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9460205918105684</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-V2</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenetv2&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenetv2/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenetv2&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7726</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9468</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.7738000000000001</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-Sketch</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet_sketch&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-sketch/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet_sketch&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7385879070133035</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9199827074613374</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.7386403921568627</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ObjectNet</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;objectnet&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/objectnet-1.0/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;objectnet&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.8059114891784215</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9387853989447615</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.797040815749882</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
</section>
<section id="multilingual-imagenet-1k">
<h3>Multilingual ImageNet-1K<a class="headerlink" href="#multilingual-imagenet-1k" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>model name</p></th>
<th class="head text-center"><p>IN-1K (EN)</p></th>
<th class="head text-center"><p>IN-1K (ZH)</p></th>
<th class="head text-center"><p>IN-1K (JP)</p></th>
<th class="head text-center"><p>IN-1K (AR)</p></th>
<th class="head text-center"><p>IN-1K (IT)</p></th>
<th class="head text-center"><p>average</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>InternVL-C</p></td>
<td class="text-center"><p>83.2</p></td>
<td class="text-center"><p>64.5</p></td>
<td class="text-center"><p>61.5</p></td>
<td class="text-center"><p>44.9</p></td>
<td class="text-center"><p>65.7</p></td>
<td class="text-center"><p>64.0</p></td>
</tr>
</tbody>
</table>
<details>
  <summary>[InternVL-C] ImageNet-1K val (ZH, Chinese)</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;cn&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet1k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-1k/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet1k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.6446</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.87842</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.6444200000000001</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;cn&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-1K val (JP, Japanese)</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;jp&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet1k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-1k/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet1k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.61488</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.81146</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.6140599999999999</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;jp&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-1K val (AR, Arabic)</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;ar&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet1k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-1k/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet1k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.4486</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.66418</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.44764</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;ar&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] ImageNet-1K val (IT, Italian)</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;it&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span>--dataset<span class="w"> </span><span class="s2">&quot;imagenet1k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/imagenet-1k/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;imagenet1k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.65686</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.85254</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.6557799999999999</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;it&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
</section>
<section id="other-datasets">
<h3>Other Datasets<a class="headerlink" href="#other-datasets" title="Permalink to this heading">#</a></h3>
<img width="1219" alt="image" src="https://github.com/OpenGVLab/InternVL/assets/23737120/5de18a6c-8979-432d-bcb6-eb7796b4a08f">
<details>
  <summary>[InternVL-C] CIFAR-10</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;cifar10&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;cifar10&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9935</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9996</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9935</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] CIFAR-100</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;cifar100&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;cifar100&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9315</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9925</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9314</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] MNIST</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;mnist&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.806</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9743</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.8028667364603377</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Caltech-101</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;caltech101&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;caltech101&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.8949037620297463</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9847987751531059</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9548738053818752</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] SUN397</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;sun397&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;sun397&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7600180223256157</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9623370174890119</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.7641970904214413</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] FGVC Aircraft</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;fgvc_aircraft&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;fgvc_aircraft&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.5271527152715272</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9426942694269427</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.5255169340463458</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Country-211</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;country211&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;country211&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.34080568720379145</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.6048815165876777</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.3406635071090047</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Stanford Cars</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;cars&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;cars&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9416739211540853</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.99950254943415</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9416684924576828</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Birdsnap</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;birdsnap&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/birdsnap/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;birdsnap&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7203252032520325</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9636856368563685</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.7027551020408164</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] DTD</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;dtd&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;dtd&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7074468085106383</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9367021276595745</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.7079787234042553</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Eurosat</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;eurosat&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;eurosat&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7937407407407407</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9984074074074074</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.8013766666666665</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] FER2013</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;fer2013&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/fer2013<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;fer2013&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.561994984675397</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9732516021175815</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.5305440899910082</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Flowers-102</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;vtab/flowers&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;vtab/flowers&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.8606277443486746</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.953651000162628</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.8563173902114554</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Food-101</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;food101&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9526336633663366</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9954851485148515</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9527524752475246</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] GTSRB</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;gtsrb&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;gtsrb&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.6548693586698338</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9089469517022961</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.5775180283147926</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Pets</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;pets&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;pets&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9604796947397111</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9991823385118561</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9602545246926443</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Rendered SST2</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;renderedsst2&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;renderedsst2&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.6792970895112576</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="n">NaN</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.6792944097041282</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] Resisc45</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;vtab/resisc45&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;vtab/resisc45&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7422631328360577</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9663545468973179</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.7481098478511045</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] STL10</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;stl10&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;stl10&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.9945</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9945</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] VOC2007</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;voc2007&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/<span class="w"> </span>--model<span class="w"> </span>internvl_c_classification<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;voc2007&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_classification&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;acc1&quot;</span><span class="p">:</span> <span class="mf">0.7997462606837606</span><span class="p">,</span> <span class="s2">&quot;acc5&quot;</span><span class="p">:</span> <span class="mf">0.9795005341880342</span><span class="p">,</span> <span class="s2">&quot;mean_per_class_recall&quot;</span><span class="p">:</span> <span class="mf">0.9048832641726575</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
</section>
</section>
<section id="evaluation-zero-shot-image-text-retrieval">
<h2>Evaluation: Zero-Shot Image-Text Retrieval<a class="headerlink" href="#evaluation-zero-shot-image-text-retrieval" title="Permalink to this heading">#</a></h2>
<section id="flickr30k-coco">
<h3>Flickr30K &amp; COCO<a class="headerlink" href="#flickr30k-coco" title="Permalink to this heading">#</a></h3>
<table class="table">
  <tr align=center>
      <td rowspan="3" align=center><b>model</b></td>
      <td colspan="6" align=center><b>Flickr30K</b></td>
      <td colspan="6" align=center><b>COCO</b></td>
      <td rowspan="3" align=center><b>avg</b></td>
</tr>
   <tr  align=center>
      <td colspan="3" align=center><b>image-to-text</b></td>
      <td colspan="3" align=center><b>text-to-image</b></td>
       <td colspan="3" align=center><b>image-to-text</b></td>
      <td colspan="3" align=center><b>text-to-image</b></td>
   </tr>
   <tr>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
   </tr>
<tr align=center>
      <td>InternVL-C</td>
      <td>94.7</td>
      <td>99.6</td>
      <td>99.9</td>
      <td>81.7</td>
      <td>96.0</td>
      <td>98.2</td>
      <td>70.6</td>
      <td>89.0</td>
      <td>93.5</td>
      <td>54.1</td>
      <td>77.3</td>
      <td>84.6</td>
      <td>86.6</td>
   </tr>
<tr align=center>
      <td>InternVL-G</td>
      <td>95.7</td>
      <td>99.7</td>
      <td>99.9</td>
      <td>85.0</td>
      <td>97.0</td>
      <td>98.6</td>
      <td>74.9</td>
      <td>91.3</td>
      <td>95.2</td>
      <td>58.6</td>
      <td>81.3</td>
      <td>88.0</td>
      <td>88.8</td>
   </tr>
</table>
<details>
  <summary>[InternVL-C] Flickr30K</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;flickr30k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/flickr30k<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;flickr30k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.8166000247001648</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.9470000267028809</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9603999853134155</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9959999918937683</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9819999933242798</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9990000128746033</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] COCO</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.5411835312843323</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7059999704360962</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.7731707096099854</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8902000188827515</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.8463414907455444</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9354000091552734</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-G] Flickr30K</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;flickr30k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/flickr30k<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;flickr30k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.8497999906539917</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.9570000171661377</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9700000286102295</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.996999979019165</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.98580002784729</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9990000128746033</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-G] COCO</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;en&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.5858056545257568</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7491999864578247</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.813194751739502</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9129999876022339</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.8795281648635864</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9521999955177307</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
</section>
<section id="flickr30k-cn-coco-cn">
<h3>Flickr30K-CN &amp; COCO-CN<a class="headerlink" href="#flickr30k-cn-coco-cn" title="Permalink to this heading">#</a></h3>
<table class="table">
  <tr  align=center>
      <td rowspan="3" align=center><b>model</b></td>
      <td colspan="6" align=center><b>Flickr30K-CN</b></td>
      <td colspan="6" align=center><b>COCO-CN</b></td>
      <td rowspan="3" align=center><b>avg</b></td>
</tr>
   <tr  align=center>
      <td colspan="3" align=center><b>image-to-text</b></td>
      <td colspan="3" align=center><b>text-to-image</b></td>
       <td colspan="3" align=center><b>image-to-text</b></td>
      <td colspan="3" align=center><b>text-to-image</b></td>
   </tr>
   <tr>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
      <td>R@1</td>
      <td>R@5</td>
      <td>R@10</td>
   </tr>
<tr align=center>
      <td>InternVL-C</td>
      <td>90.3</td>
      <td>98.8</td>
      <td>99.7</td>
      <td>75.1</td>
      <td>92.9</td>
      <td>96.4</td>
      <td>68.8</td>
      <td>92.0</td>
      <td>96.7</td>
      <td>68.9</td>
      <td>91.9</td>
      <td>96.5</td>
      <td>89.0</td>
   </tr>
<tr align=center>
      <td>InternVL-G</td>
      <td>92.9</td>
      <td>99.4</td>
      <td>99.8</td>
      <td>77.7</td>
      <td>94.8</td>
      <td>97.3</td>
      <td>71.4</td>
      <td>93.9</td>
      <td>97.7</td>
      <td>73.8</td>
      <td>94.4</td>
      <td>98.1</td>
      <td>90.9</td>
   </tr>
</table>
<details>
  <summary>[InternVL-C] Flickr30K-CN</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;cn&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;flickr30k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/flickr30k<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;flickr30k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7509999871253967</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.902999997138977</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9290000200271606</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9879999756813049</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9638000130653381</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.996999979019165</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;cn&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-C] COCO-CN</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;cn&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6885090470314026</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6880000233650208</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9192782640457153</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9200000166893005</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9648622870445251</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9670000076293945</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;cn&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-G] Flickr30K-CN</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;cn&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;flickr30k&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/flickr30k<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;flickr30k&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7767999768257141</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.9290000200271606</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9476000070571899</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9940000176429749</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9728000164031982</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9980000257492065</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;cn&quot;</span><span class="p">}</span>

</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-G] COCO-CN</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--language<span class="w"> </span><span class="s2">&quot;cn&quot;</span><span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span>
<span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7378917336463928</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7139999866485596</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9439696073532104</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9390000104904175</span><span class="p">,</span>
<span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9810066223144531</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9769999980926514</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;cn&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
</section>
<section id="xtd">
<h3>XTD<a class="headerlink" href="#xtd" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>model name</p></th>
<th class="head text-center"><p>EN</p></th>
<th class="head text-center"><p>ES</p></th>
<th class="head text-center"><p>FR</p></th>
<th class="head text-center"><p>ZH</p></th>
<th class="head text-center"><p>IT</p></th>
<th class="head text-center"><p>KO</p></th>
<th class="head text-center"><p>RU</p></th>
<th class="head text-center"><p>JP</p></th>
<th class="head text-center"><p>average</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>InternVL-C</p></td>
<td class="text-center"><p>97.3</p></td>
<td class="text-center"><p>95.7</p></td>
<td class="text-center"><p>95.1</p></td>
<td class="text-center"><p>95.6</p></td>
<td class="text-center"><p>96.0</p></td>
<td class="text-center"><p>92.2</p></td>
<td class="text-center"><p>93.3</p></td>
<td class="text-center"><p>95.5</p></td>
<td class="text-center"><p>95.1</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>InternVL-G</p></td>
<td class="text-center"><p>98.6</p></td>
<td class="text-center"><p>97.7</p></td>
<td class="text-center"><p>96.5</p></td>
<td class="text-center"><p>96.7</p></td>
<td class="text-center"><p>96.9</p></td>
<td class="text-center"><p>95.1</p></td>
<td class="text-center"><p>94.8</p></td>
<td class="text-center"><p>96.1</p></td>
<td class="text-center"><p>96.6</p></td>
</tr>
</tbody>
</table>
<details>
  <summary>[InternVL-C] XTD</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>en

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>es

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>fr

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>zh

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>it

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>ko

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>ru

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_c_retrieval<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_c_13b_224px.pth<span class="w"> </span>--output<span class="w"> </span>result.json<span class="w"> </span>--language<span class="o">=</span>jp
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7670000195503235</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7480000257492065</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9200000166893005</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.921999990940094</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9670000076293945</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9729999899864197</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7059999704360962</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7009999752044678</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9020000100135803</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8960000276565552</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9430000185966492</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9570000171661377</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;es&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6970000267028809</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6899999976158142</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8830000162124634</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8889999985694885</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9350000023841858</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9509999752044678</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;fr&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6480000019073486</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6710000038146973</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8759999871253967</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8769999742507935</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9419999718666077</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9559999704360962</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;zh&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6790000200271606</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7039999961853027</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8989999890327454</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8999999761581421</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9440000057220459</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9599999785423279</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;it&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.5830000042915344</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.5920000076293945</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8399999737739563</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8360000252723694</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9079999923706055</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.921999990940094</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;ko&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6430000066757202</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6439999938011169</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8510000109672546</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8640000224113464</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9169999957084656</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9330000281333923</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;ru&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_c_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_c_13b_224px.pth&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6330000162124634</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6759999990463257</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.875</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8989999890327454</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9359999895095825</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9549999833106995</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;jp&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
<details>
  <summary>[InternVL-G] XTD</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>en

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>es

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>fr

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>zh

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>it

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>ko

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>ru

<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python3<span class="w"> </span>clip_benchmark/cli.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--model_type<span class="w"> </span>internvl<span class="w"> </span>--task<span class="w"> </span><span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="w"> </span>--dataset_root<span class="w"> </span>./data/mscoco_captions<span class="w"> </span>--model<span class="w"> </span>internvl_g_retrieval_hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pretrained<span class="w"> </span>./pretrained/internvl_14b_224px<span class="w"> </span>--output<span class="w"> </span>result_g.json<span class="w"> </span>--language<span class="o">=</span>jp
</pre></div>
</div>
<p>Expected results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.8119999766349792</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7979999780654907</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9470000267028809</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9480000138282776</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9829999804496765</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9860000014305115</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;en&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7549999952316284</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7450000047683716</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9350000023841858</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.925000011920929</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9660000205039978</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9769999980926514</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;es&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7450000047683716</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7279999852180481</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9179999828338623</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9190000295639038</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9620000123977661</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9649999737739563</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;fr&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6980000138282776</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6949999928474426</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9120000004768372</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9110000133514404</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9620000123977661</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9670000076293945</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;zh&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7329999804496765</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.7450000047683716</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9309999942779541</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9309999942779541</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9639999866485596</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.968999981880188</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;it&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6430000066757202</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6470000147819519</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8790000081062317</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8769999742507935</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9419999718666077</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9509999752044678</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;ko&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6850000023841858</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6899999976158142</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8740000128746033</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.8920000195503235</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9390000104904175</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9480000138282776</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;ru&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="s2">&quot;dataset&quot;</span><span class="p">:</span> <span class="s2">&quot;multilingual_mscoco_captions&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;internvl_g_retrieval_hf&quot;</span><span class="p">,</span> <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="s2">&quot;./pretrained/internvl_14b_224px&quot;</span><span class="p">,</span> <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;zeroshot_retrieval&quot;</span><span class="p">,</span> <span class="s2">&quot;metrics&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;image_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.6850000023841858</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@1&quot;</span><span class="p">:</span> <span class="mf">0.703000009059906</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9020000100135803</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@5&quot;</span><span class="p">:</span> <span class="mf">0.9100000262260437</span><span class="p">,</span> <span class="s2">&quot;image_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9539999961853027</span><span class="p">,</span> <span class="s2">&quot;text_retrieval_recall@10&quot;</span><span class="p">:</span> <span class="mf">0.9610000252723694</span><span class="p">},</span> <span class="s2">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;jp&quot;</span><span class="p">}</span>
</pre></div>
</div>
</details>
</section>
</section>
<section id="original-readme-of-clip-benchmark">
<h2>Original README of CLIP Benchmark<a class="headerlink" href="#original-readme-of-clip-benchmark" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://pypi.python.org/pypi/clip_benchmark"><img alt="pypi" src="https://img.shields.io/pypi/v/clip_benchmark.svg" /></a></p>
<p>The goal of this repo is to evaluate CLIP-like models on a standard set
of datasets on different tasks such as zero-shot classification and zero-shot
retrieval.</p>
<p>Below we show the average rank (1 is the best, lower is better) of different CLIP models, evaluated
on different datasets.</p>
<p><img alt="benchmark.png" src="../_images/clip_benchmark2.png" /></p>
<p>The current detailed results of the benchmark can be seen <a class="reference internal" href="#benchmark/README.md"><span class="xref myst">here</span></a>
or directly in the <a class="reference internal" href="#benchmark/results.ipynb"><span class="xref myst">notebook</span></a>.</p>
<section id="features">
<h3>Features<a class="headerlink" href="#features" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Support for zero-shot classification and zero-shot retrieval</p></li>
<li><p>Support for <a class="reference external" href="https://github.com/mlfoundations/open_clip">OpenCLIP</a> pre-trained models</p></li>
<li><p>Support various datasets from <a class="reference external" href="https://pytorch.org/vision/stable/datasets.html">torchvision</a>, <a class="reference external" href="https://www.tensorflow.org/datasets">tensorflow datasets</a>, and <a class="reference external" href="https://github.com/google-research/task_adaptation">VTAB</a>.</p></li>
<li><p>Support <a class="reference external" href="https://github.com/rinnakk/japanese-clip">Japanese CLIP by rinna</a></p></li>
</ul>
</section>
<section id="how-to-install">
<h3>How to install?<a class="headerlink" href="#how-to-install" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">clip-benchmark</span></code></p>
</section>
<section id="how-to-use">
<h3>How to use?<a class="headerlink" href="#how-to-use" title="Permalink to this heading">#</a></h3>
<p>To evaluate we recommend to create a models.txt like</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ViT</span><span class="o">-</span><span class="n">B</span><span class="o">-</span><span class="mi">32</span><span class="p">,</span><span class="n">openai</span>
</pre></div>
</div>
<p>to get the list of datasets</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">LAION</span><span class="o">-</span><span class="n">AI</span><span class="o">/</span><span class="n">CLIP_benchmark</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">benchmark</span><span class="o">/</span><span class="n">webdatasets</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<p>Then to run</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clip_benchmark</span> <span class="nb">eval</span> <span class="o">--</span><span class="n">pretrained_model</span> <span class="n">models</span><span class="o">.</span><span class="n">txt</span> \
    <span class="o">--</span><span class="n">dataset</span> <span class="s2">&quot;webdatasets.txt&quot;</span> \
    <span class="o">--</span><span class="n">dataset_root</span> <span class="s2">&quot;https://huggingface.co/datasets/clip-benchmark/wds_</span><span class="si">{dataset_cleaned}</span><span class="s2">/tree/main&quot;</span> \
    <span class="o">--</span><span class="n">output</span> <span class="s2">&quot;benchmark_</span><span class="si">{dataset}</span><span class="s2">_</span><span class="si">{pretrained}</span><span class="s2">_</span><span class="si">{model}</span><span class="s2">_</span><span class="si">{language}</span><span class="s2">_</span><span class="si">{task}</span><span class="s2">.json&quot;</span>
</pre></div>
</div>
<p>Then to get the full table</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clip_benchmark</span> <span class="n">build</span> <span class="n">benchmark_</span><span class="o">*.</span><span class="n">json</span> <span class="o">--</span><span class="n">output</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
<section id="command-line-interface-cli">
<h4>Command line interface (CLI)<a class="headerlink" href="#command-line-interface-cli" title="Permalink to this heading">#</a></h4>
<p>The easiest way to benchmark the models is using the CLI, <code class="docutils literal notranslate"><span class="pre">clip_benchmark</span></code>.
You can specify the model to use, the dataset and the task to evaluate on. Once it is done, evaluation is performed and
the results are written into a JSON file.</p>
</section>
<section id="using-other-models-than-openclip">
<h4>Using other models than openclip<a class="headerlink" href="#using-other-models-than-openclip" title="Permalink to this heading">#</a></h4>
<p>It is possible to use other models than openclip ones. For example japanese-clip is supported</p>
<p>Here is an example of use</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">python3</span> <span class="n">clip_benchmark</span><span class="o">/</span><span class="n">cli</span><span class="o">.</span><span class="n">py</span> <span class="nb">eval</span> \
<span class="go">  --model_type &quot;ja_clip&quot; \ # flag to use japanese-clip</span>
<span class="go">  --pretrained &quot;rinna/japanese-cloob-vit-b-16&quot; \ # now, we have `rinna/japanese-cloob-vit-b-16` or `rinna/japanese-clip-vit-b-16`.</span>
<span class="go">  --language &quot;jp&quot; \</span>
<span class="go">  --task &quot;zeroshot_classification&quot;  \</span>
<span class="go">  --dataset &quot;imagenet1k&quot;  \</span>
<span class="go">  --dataset_root {ROOT_PATH}</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">cat</span> <span class="n">result</span><span class="o">.</span><span class="n">json</span>
<span class="go">{&quot;dataset&quot;: &quot;imagenet1k&quot;, &quot;model&quot;: &quot;ViT-B-32-quickgelu&quot;, &quot;pretrained&quot;: &quot;rinna/japanese-cloob-vit-b-16&quot;, &quot;task&quot;: &quot;zeroshot_classification&quot;, &quot;metrics&quot;: {&quot;acc1&quot;: 0.54636, &quot;acc5&quot;: 0.72856, &quot;mean_per_class_recall&quot;: 0.54522}, &quot;language&quot;: &quot;jp&quot;}</span>
</pre></div>
</div>
</section>
<section id="how-to-add-other-clip-models">
<h4>How to add other CLIP models<a class="headerlink" href="#how-to-add-other-clip-models" title="Permalink to this heading">#</a></h4>
<p>Please follow these steps:</p>
<ol class="arabic simple">
<li><p>Add a identity file to load model in <code class="docutils literal notranslate"><span class="pre">clip_benchmark/models</span></code></p></li>
<li><p>Define a loading function, that returns a tuple (model, transform, tokenizer). Please see <code class="docutils literal notranslate"><span class="pre">clip_benchmark/models/open_clip.py</span></code> as an example.</p></li>
<li><p>Add the function into <code class="docutils literal notranslate"><span class="pre">TYPE2FUNC</span></code> in <code class="docutils literal notranslate"><span class="pre">clip_benchmark/models/__init__.py</span></code></p></li>
</ol>
<p>Remarks:</p>
<ul class="simple">
<li><p>The new tokenizer/model must enable to do the following things as https://github.com/openai/CLIP#usage</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">tokenizer(texts).to(device)</span></code>  … <code class="docutils literal notranslate"><span class="pre">texts</span></code> is a list of string</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.encode_text(tokenized_texts)</span></code> … <code class="docutils literal notranslate"><span class="pre">tokenized_texts</span></code> is a output from <code class="docutils literal notranslate"><span class="pre">tokenizer(texts).to(device)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.encode_image(images)</span></code> … <code class="docutils literal notranslate"><span class="pre">images</span></code> is a image tensor by the <code class="docutils literal notranslate"><span class="pre">transform</span></code></p></li>
</ul>
</li>
</ul>
</section>
<section id="cifar-10-example">
<h4>CIFAR-10 example<a class="headerlink" href="#cifar-10-example" title="Permalink to this heading">#</a></h4>
<p>Here is an example for CIFAR-10 zero-shot classification using OpenCLIP’s pre-trained model on LAION-400m:</p>
<p><code class="docutils literal notranslate"><span class="pre">clip_benchmark</span> <span class="pre">eval</span> <span class="pre">--dataset=cifar10</span> <span class="pre">--task=zeroshot_classification</span> <span class="pre">--pretrained=laion400m_e32</span> <span class="pre">--model=ViT-B-32-quickgelu</span> <span class="pre">--output=result.json</span> <span class="pre">--batch_size=64</span></code></p>
<p>By default, the dataset is downloaded into <code class="docutils literal notranslate"><span class="pre">--dataset_root</span></code>, which by default is <code class="docutils literal notranslate"><span class="pre">root</span></code>.</p>
<p>Here is the content of <code class="docutils literal notranslate"><span class="pre">result.json</span></code> after the evaluation is done:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cifar10&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ViT-B-32-quickgelu&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;pretrained&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;laion400m_e32&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;task&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;acc1&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.9074</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;acc5&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.998</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="voc2007-example">
<h4>VOC2007 example<a class="headerlink" href="#voc2007-example" title="Permalink to this heading">#</a></h4>
<p>Here is another example with VOC2007, which is a multi-label classification dataset.</p>
<p><code class="docutils literal notranslate"><span class="pre">clip_benchmark</span> <span class="pre">eval</span> <span class="pre">--dataset=voc2007_multilabel</span> <span class="pre">--task=zeroshot_classification</span> <span class="pre">--pretrained=laion400m_e32</span> <span class="pre">--model=ViT-B-32-quickgelu</span> <span class="pre">--output=result.json</span> <span class="pre">--batch_size=64</span></code></p>
<p>Here is the content of <code class="docutils literal notranslate"><span class="pre">result.json</span></code> after the evaluation is done:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;voc2007_multilabel&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ViT-B-32-quickgelu&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;pretrained&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;laion400m_e32&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;task&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;zeroshot_classification&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;metrics&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;mean_average_precision&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.7627869844436646</span><span class="p">}}</span>
</pre></div>
</div>
<p>Here, we compute the mean average precision or mAP, more details about that metric <a class="reference external" href="https://fangdahan.medium.com/calculate-mean-average-precision-map-for-multi-label-classification-b082679d31be">here</a> in the context of multi-label classification.</p>
</section>
<section id="vtab-example">
<h4>VTAB example<a class="headerlink" href="#vtab-example" title="Permalink to this heading">#</a></h4>
<p>Here is an example on how to run it on <a class="reference external" href="https://github.com/google-research/task_adaptation">VTAB</a> classification tasks.
First, you need to install VTAB’s dedicated package.</p>
<p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">task_adaptation==0.1</span></code></p>
<p>Then, you can run it by providing the full dataset name.
Example with <code class="docutils literal notranslate"><span class="pre">eurosat</span></code>:</p>
<p><code class="docutils literal notranslate"><span class="pre">clip_benchmark</span> <span class="pre">eval</span> <span class="pre">--dataset=vtab/eurosat</span> <span class="pre">--task=zeroshot_classification</span> <span class="pre">--pretrained=laion400m_e32</span> <span class="pre">--model=ViT-B-32-quickgelu</span> <span class="pre">--output=result.json</span> <span class="pre">--batch_size=64</span></code></p>
<p>See <a class="reference internal" href="#clip_benchmark/datasets/builder.py#L634"><span class="xref myst">clip_benchmark/datasets/builder.py#L634</span></a> for the full list of
VTAB dataset collection.</p>
</section>
<section id="tensorflow-dataset-example">
<h4>TensorFlow dataset example<a class="headerlink" href="#tensorflow-dataset-example" title="Permalink to this heading">#</a></h4>
<p>Here is an example on how to run it on <a class="reference external" href="https://www.tensorflow.org/datasets">Tensorflow datasets</a>.
First, you need to install <code class="docutils literal notranslate"><span class="pre">tfds-nightly</span></code> and <code class="docutils literal notranslate"><span class="pre">timm</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">timm</span> <span class="pre">tfds-nightly</span></code></p>
<p>The name of the dataset follows the template <code class="docutils literal notranslate"><span class="pre">tfds/&lt;DATASET_NAME&gt;</span></code>.</p>
<p>Example with <code class="docutils literal notranslate"><span class="pre">cifar10</span></code>:</p>
<p><code class="docutils literal notranslate"><span class="pre">clip_benchmark</span> <span class="pre">eval</span> <span class="pre">--dataset=tfds/cifar10</span> <span class="pre">--task=zeroshot_classification</span> <span class="pre">--pretrained=laion400m_e32</span> <span class="pre">--model=ViT-B-32-quickgelu</span> <span class="pre">--output=result.json</span> <span class="pre">--batch_size=64</span></code></p>
</section>
<section id="coco-captions-example">
<h4>COCO captions example<a class="headerlink" href="#coco-captions-example" title="Permalink to this heading">#</a></h4>
<p>Here is an example for COCO captions zero-shot retrieval:</p>
<p><code class="docutils literal notranslate"><span class="pre">clip_benchmark</span> <span class="pre">eval</span> <span class="pre">--dataset=mscoco_captions</span> <span class="pre">--task=zeroshot_retrieval</span> <span class="pre">--pretrained=laion400m_e32</span> <span class="pre">--model=ViT-B-32-quickgelu</span> <span class="pre">--output=result.json</span> <span class="pre">--batch_size=64</span></code></p>
<p>Note that for using COCO, you also need to install <code class="docutils literal notranslate"><span class="pre">pycocotools</span></code> (e.g., using <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">pycocotools</span></code>).</p>
</section>
<section id="webdataset-example">
<h4>Webdataset example<a class="headerlink" href="#webdataset-example" title="Permalink to this heading">#</a></h4>
<p>Here is an example on how to run it on <a class="reference external" href="https://github.com/webdataset/webdataset">webdatasets</a>.
First, you need to install <code class="docutils literal notranslate"><span class="pre">webdataset</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">webdataset</span></code></p>
<section id="creating-a-webdataset">
<h5>Creating a webdataset<a class="headerlink" href="#creating-a-webdataset" title="Permalink to this heading">#</a></h5>
<p>You can either convert an already supported CLIP_benchmark dataset to webdataset format, or manually create your own with the same file structure. For already supported datasets use the CLI command <code class="docutils literal notranslate"><span class="pre">clip_benchmark_export_wds</span></code> as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ clip_benchmark_export_wds --dataset cifar10 --split train --dataset_root DATA_DIR/ --output wds_cifar10/
$ clip_benchmark_export_wds --dataset cifar10 --split test --dataset_root DATA_DIR/ --output wds_cifar10/
</pre></div>
</div>
<p>which will convert the train and test splits for CIFAR-10 (downloaded to <code class="docutils literal notranslate"><span class="pre">DATA_DIR/</span></code>) and save the webdataset to <code class="docutils literal notranslate"><span class="pre">wds_cifar10/</span></code> (upload to Huggingface Hub must be done manually for now). Retrieval datasets are also supported with the <code class="docutils literal notranslate"><span class="pre">--retrieval</span></code> flag.</p>
<p>For other datasets, data must be stored with the following file structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root_dir</span><span class="o">/</span>
    <span class="n">train</span><span class="o">/</span>
        <span class="n">nshards</span><span class="o">.</span><span class="n">txt</span>
        <span class="mf">0.</span><span class="n">tar</span>
        <span class="mf">1.</span><span class="n">tar</span>
        <span class="o">...</span>
    <span class="n">test</span><span class="o">/</span>
        <span class="n">nshards</span><span class="o">.</span><span class="n">txt</span>
        <span class="mf">0.</span><span class="n">tar</span>
        <span class="o">...</span>
    <span class="n">classnames</span><span class="o">.</span><span class="n">txt</span>
    <span class="n">zeroshot_classification_templates</span><span class="o">.</span><span class="n">txt</span>
    <span class="n">dataset_type</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<p>Each split should be contained in its own folder and <code class="docutils literal notranslate"><span class="pre">nshards.txt</span></code> should contain a single integer corresponding to the number of TAR files. The TAR files should follow webdataset format, with an image file (.webp, .png, or .jpg) and a label (.cls) for each example. Classnames and templates are required for zeroshot classification evaluation, with each classname or template on its own line. Dataset type is required for distinguishing zeroshot retrieval evaluation: the file should just contain the text <code class="docutils literal notranslate"><span class="pre">retrieval</span></code>.</p>
</section>
<section id="evaluating-on-a-webdataset">
<h5>Evaluating on a webdataset<a class="headerlink" href="#evaluating-on-a-webdataset" title="Permalink to this heading">#</a></h5>
<p>The name of the dataset follows the template <code class="docutils literal notranslate"><span class="pre">wds/&lt;DATASET_NAME&gt;</span></code>. Note that the dataset name currently only affects the name in the results output - classnames and templates are loaded directly from the included files. The dataset root directory can be either a local path to the <code class="docutils literal notranslate"><span class="pre">root_dir</span></code> as specified above, or an HTTP URL pointing to a Huggingface Hub dataset file tree.</p>
<p>Example with <code class="docutils literal notranslate"><span class="pre">vtab/cifar10</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ clip_benchmark eval --dataset wds/vtab/cifar10 --dataset_root ROOT_DIR/wds_vtab-cifar10/
$ clip_benchmark eval --dataset wds/vtab/cifar10 --dataset_root https://huggingface.co/datasets/clip-benchmark/wds_vtab-cifar10/tree/main
</pre></div>
</div>
<p>All other arguments remain the same as in the other examples. See <code class="docutils literal notranslate"><span class="pre">https://huggingface.co/clip-benchmark</span></code> for a full list of datasets that have already been uploaded to Huggingface.</p>
</section>
</section>
</section>
<section id="evaluate-mulitple-models-on-multiple-datasets">
<h3>Evaluate mulitple models on multiple datasets<a class="headerlink" href="#evaluate-mulitple-models-on-multiple-datasets" title="Permalink to this heading">#</a></h3>
<p>For the purpose of benchmarking, it is possible to run the CLI with multiple
pre-trained models on multiple datasets.</p>
<section id="pretrained-models-and-datasets-list-as-arguments">
<h4>Pretrained models and datasets list as arguments<a class="headerlink" href="#pretrained-models-and-datasets-list-as-arguments" title="Permalink to this heading">#</a></h4>
<p>For models, we can provide list of pretrained model names in the form of ‘model,pretrained’ (so <code class="docutils literal notranslate"><span class="pre">model</span></code> and <code class="docutils literal notranslate"><span class="pre">pretrained</span></code> are comma separated). For datasets, we can provide a list of datasets.  For languages, we can provide a list of languages.
Example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clip_benchmark<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--pretrained_model<span class="w">  </span>ViT-B-32-quickgelu,laion400m_e32<span class="w"> </span>ViT-L-14,laion400m_e32<span class="w">  </span><span class="se">\</span>
--dataset<span class="w"> </span>cifar10<span class="w"> </span>cifar100<span class="w"> </span>--dataset_root<span class="w"> </span><span class="s2">&quot;clip_benchmark_datasets/{dataset}&quot;</span><span class="w"> </span>--language<span class="w"> </span>en<span class="w"> </span>jp<span class="w"> </span><span class="se">\</span>
<span class="w"> </span>--output<span class="w"> </span><span class="s2">&quot;{dataset}_{pretrained}_{model}_{language}_{task}.json&quot;</span>
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">--dataset_root</span></code> and <code class="docutils literal notranslate"><span class="pre">--output</span></code> can be now in the form of a template that depends on the dataset/model/language/task (for <code class="docutils literal notranslate"><span class="pre">--output</span></code>) and dataset name (for <code class="docutils literal notranslate"><span class="pre">--dataset_root</span></code>).</p>
<p>Note that If the benchmark fails at some point, it is possible to resume it by skipping already evaluated models using <code class="docutils literal notranslate"><span class="pre">--skip_existing</span></code>.</p>
</section>
<section id="pretrained-models-and-datasets-list-as-files">
<h4>Pretrained models and datasets list as files<a class="headerlink" href="#pretrained-models-and-datasets-list-as-files" title="Permalink to this heading">#</a></h4>
<p>We can also provide a path to files with models (each line is in the form of ‘model,pretrained’ where <code class="docutils literal notranslate"><span class="pre">model</span></code> and <code class="docutils literal notranslate"><span class="pre">pretrained</span></code> are comma separated) and datasets list (one dataset per line):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clip_benchmark<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--pretrained_model<span class="w">  </span>benchmark/models.txt<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>benchmark/datasets.txt<span class="w"> </span>--dataset_root<span class="w"> </span><span class="s2">&quot;clip_benchmark_datasets/{dataset}&quot;</span><span class="w">  </span><span class="se">\</span>
<span class="w"> </span>--output<span class="w"> </span><span class="s2">&quot;{dataset}_{pretrained}_{model}_{language}_{task}.json&quot;</span>
</pre></div>
</div>
<p>Examples are available in <a class="reference internal" href="#benchmark/datasets.txt"><span class="xref myst">benchmark/datasets.txt</span></a> and <a class="reference internal" href="#benchmark/models.txt"><span class="xref myst">benchmark/models.txt</span></a></p>
</section>
<section id="model-and-dataset-collections">
<h4>Model and dataset collections<a class="headerlink" href="#model-and-dataset-collections" title="Permalink to this heading">#</a></h4>
<p>We can also provide model collection names (<code class="docutils literal notranslate"><span class="pre">openai</span></code>, <code class="docutils literal notranslate"><span class="pre">openclip_base</span></code>, <code class="docutils literal notranslate"><span class="pre">openclip_multilingual</span></code>, <code class="docutils literal notranslate"><span class="pre">openclip_full</span></code> are supported) or dataset collection names (<code class="docutils literal notranslate"><span class="pre">vtab</span></code>, <code class="docutils literal notranslate"><span class="pre">vtab+</span></code>, <code class="docutils literal notranslate"><span class="pre">retrieval</span></code>, <code class="docutils literal notranslate"><span class="pre">imagenet_robustness</span></code> are supported):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clip_benchmark<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>--pretrained_model<span class="w"> </span>openai<span class="w"> </span>openclip_base<span class="w">  </span>--dataset<span class="w"> </span>vtab+<span class="w"> </span>retrieval<span class="w"> </span><span class="se">\</span>
--dataset_root<span class="w"> </span><span class="s2">&quot;clip_benchmark_datasets/{dataset}&quot;</span><span class="w"> </span>--not<span class="w"> </span>quiet<span class="w"> </span><span class="se">\</span>
--output<span class="w"> </span><span class="s2">&quot;{dataset}_{pretrained}_{model}_{language}_{task}.json&quot;</span>
</pre></div>
</div>
</section>
<section id="development">
<h4>Development<a class="headerlink" href="#development" title="Permalink to this heading">#</a></h4>
<p>For development, you can also do this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/LAION-AI/CLIP_benchmark
<span class="nb">cd</span><span class="w"> </span>CLIP_benchmark
python<span class="w"> </span>setup.py<span class="w"> </span>install
</pre></div>
</div>
</section>
</section>
<section id="credits">
<h3>Credits<a class="headerlink" href="#credits" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Thanks to <a class="reference external" href="https://github.com/mlfoundations/open_clip">OpenCLIP</a> authors, zero-shot accuracy code is adapted from there and pre-trained models are used in the command line interface.</p></li>
<li><p>Thanks to <a class="reference external" href="https://github.com/facebookresearch/SLIP">SLIP</a> authors, some zero-shot templates and classnames are from there.</p></li>
<li><p>Thanks to <a class="reference external" href="https://github.com/mlfoundations/wise-ft">Wise-ft</a> authors, Imagenet robustness datasets code is adapted from there</p></li>
<li><p>Thanks to <a class="reference external" href="https://arxiv.org/abs/2111.07991.pdf">LiT</a> authors, some zero-shot templates and classnames of VTAB datasets are from there.</p></li>
<li><p>This package was created with <a class="reference external" href="https://github.com/audreyr/cookiecutter">Cookiecutter</a> and the <a class="reference external" href="https://github.com/audreyr/cookiecutter-pypackage">audreyr/cookiecutter-pypackage</a> project template. Thanks to the author.</p></li>
</ul>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installation">Installation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-preparation">Model Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-zero-shot-image-classification">Evaluation: Zero-Shot Image Classification</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#imagenet-variants-and-objectnet">ImageNet variants and ObjectNet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multilingual-imagenet-1k">Multilingual ImageNet-1K</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-datasets">Other Datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-zero-shot-image-text-retrieval">Evaluation: Zero-Shot Image-Text Retrieval</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#flickr30k-coco">Flickr30K &amp; COCO</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#flickr30k-cn-coco-cn">Flickr30K-CN &amp; COCO-CN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xtd">XTD</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#original-readme-of-clip-benchmark">Original README of CLIP Benchmark</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#features">Features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-install">How to install?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use">How to use?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#command-line-interface-cli">Command line interface (CLI)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-other-models-than-openclip">Using other models than openclip</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-add-other-clip-models">How to add other CLIP models</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cifar-10-example">CIFAR-10 example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#voc2007-example">VOC2007 example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vtab-example">VTAB example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-dataset-example">TensorFlow dataset example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coco-captions-example">COCO captions example</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#webdataset-example">Webdataset example</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-webdataset">Creating a webdataset</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-on-a-webdataset">Evaluating on a webdataset</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-mulitple-models-on-multiple-datasets">Evaluate mulitple models on multiple datasets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pretrained-models-and-datasets-list-as-arguments">Pretrained models and datasets list as arguments</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pretrained-models-and-datasets-list-as-files">Pretrained models and datasets list as files</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-and-dataset-collections">Model and dataset collections</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#development">Development</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credits">Credits</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By InternVL Authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, OpenGVLab.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Jul 25, 2024.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>