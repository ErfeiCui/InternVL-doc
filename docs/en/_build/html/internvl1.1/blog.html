

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>InternVL-Chat &#8212; internvl</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/readthedocs.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'internvl1.1/blog';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 25, 2024"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/internvl-logo.svg" class="logo__image only-light" alt="internvl - Home"/>
    <script>document.write(`<img src="../_static/internvl-logo.svg" class="logo__image only-dark" alt="internvl - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/installation.html">Installation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">InternVL 1.1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="internvl_chat.html">internvl_chat</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">InternVL 1.0</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/clip_benchmark.html">clip_benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/segmentation.html">segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/internvl_chat_llava.html">internvl_chat_llava</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internvl1.0/internvl_g.html">internvl_g</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL/blob/main/docs/en/internvl1.1/blog.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL/edit/main/docs/en/internvl1.1/blog.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/OpenGVLab/InternVL/issues/new?title=Issue%20on%20page%20%2Finternvl1.1/blog.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/internvl1.1/blog.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>InternVL-Chat</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installation">🛠️ Installation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-preparation">📦 Model Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">🔥 Supervised Fine-tuning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-datasets">Prepare Training Datasets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-training">Start Training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continued-fine-tune">Continued Fine-tune</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">📊 Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-legacy-models">📊 Evaluation (Legacy Models)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-evaluate">❓ How to Evaluate</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-caption-benchmarks">Image Caption Benchmarks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coco-karpathy-test">COCO Karpathy test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#flickr30k-karpathy-test">Flickr30K Karpathy test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#nocaps-val">NoCaps val</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-vqa-benchmarks">General VQA Benchmarks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vqav2-val-test-dev">VQAv2 val &amp; test-dev</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#okvqa-val">OKVQA val</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#textvqa-val">TextVQA val</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vizwiz-val-test">VizWiz val &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#docvqa-val-test">DocVQA val &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#chartqa-test-human-test-augmented">ChartQA test-human &amp; test-augmented</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gqa-testdev">GQA testdev</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ocrvqa-val-test">OCRVQA val &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ai2d-test">AI2D test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scienceqa-test">ScienceQA test</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#refer-expression-comprehension">Refer Expression Comprehension</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#refcoco-refcoco-refcoco-g">RefCOCO/RefCOCO+/RefCOCO-g</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-benchmarks">MultiModal Benchmarks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mme">MME</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mmbench-dev-test">MMBench dev &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pope">POPE</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mmmu"><span class="xref myst">MMMU</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-lvlm">Tiny LVLM</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#llava-bench">LLaVA Bench</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mm-vet">MM-Vet</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mmvp">MMVP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mathvista">MathVista</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#seed">SEED</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="internvl-chat">
<h1>InternVL-Chat<a class="headerlink" href="#internvl-chat" title="Permalink to this heading">#</a></h1>
<p>This folder contains the implementation of the InternVL-Chat.</p>
<section id="installation">
<h2>🛠️ Installation<a class="headerlink" href="#installation" title="Permalink to this heading">#</a></h2>
<p>See <a class="reference internal" href="#../INSTALLATION.md"><span class="xref myst">INSTALLATION.md</span></a></p>
<p>In addition, using this codebase requires executing the following steps:</p>
<ul>
<li><p>Install other requirements:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip<span class="w">  </span><span class="c1"># enable PEP 660 support</span>
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</li>
</ul>
</section>
<section id="model-preparation">
<h2>📦 Model Preparation<a class="headerlink" href="#model-preparation" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model name</p></th>
<th class="head"><p>type</p></th>
<th class="head"><p>download</p></th>
<th class="head text-center"><p>size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>InternViT-300M-448px</p></td>
<td><p>ViT</p></td>
<td><p>🤗 <a class="reference external" href="https://huggingface.co/OpenGVLab/InternViT-300M-448px">HF link</a></p></td>
<td class="text-center"><p>0.6 GB</p></td>
</tr>
<tr class="row-odd"><td><p>InternViT-6B-448px-V1-2</p></td>
<td><p>ViT</p></td>
<td><p>🤗 <a class="reference external" href="https://huggingface.co/OpenGVLab/InternViT-6B-448px-V1-2">HF link</a></p></td>
<td class="text-center"><p>11.1 GB</p></td>
</tr>
<tr class="row-even"><td><p>InternViT-6B-448px-V1-5</p></td>
<td><p>ViT</p></td>
<td><p>🤗 <a class="reference external" href="https://huggingface.co/OpenGVLab/InternViT-6B-448px-V1-5">HF link</a></p></td>
<td class="text-center"><p>11.1 GB</p></td>
</tr>
<tr class="row-odd"><td><p>Nous-Hermes-2-Yi-34B</p></td>
<td><p>LLM</p></td>
<td><p>🤗 <a class="reference external" href="https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B">HF link</a></p></td>
<td class="text-center"><p>65.0 GB</p></td>
</tr>
</tbody>
</table>
<p>Please download the above model weights and place them in the <code class="docutils literal notranslate"><span class="pre">pretrained/</span></code> folder.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>pretrained/
<span class="c1"># pip install -U huggingface_hub</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--resume-download<span class="w"> </span>--local-dir-use-symlinks<span class="w"> </span>False<span class="w"> </span>OpenGVLab/InternViT-300M-448px<span class="w"> </span>--local-dir<span class="w"> </span>InternViT-300M-448px
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--resume-download<span class="w"> </span>--local-dir-use-symlinks<span class="w"> </span>False<span class="w"> </span>OpenGVLab/InternViT-6B-448px-V1-2<span class="w"> </span>--local-dir<span class="w"> </span>InternViT-6B-448px-V1-2
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--resume-download<span class="w"> </span>--local-dir-use-symlinks<span class="w"> </span>False<span class="w"> </span>OpenGVLab/InternViT-6B-448px-V1-5<span class="w"> </span>--local-dir<span class="w"> </span>InternViT-6B-448px-V1-5
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--resume-download<span class="w"> </span>--local-dir-use-symlinks<span class="w"> </span>False<span class="w"> </span>NousResearch/Nous-Hermes-2-Yi-34B<span class="w"> </span>--local-dir<span class="w"> </span>Nous-Hermes-2-Yi-34B
</pre></div>
</div>
<p>The directory structure is:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pretrained
│──<span class="w"> </span>InternViT-300M-448px/
│──<span class="w"> </span>InternViT-6B-448px-V1-2/
│──<span class="w"> </span>InternViT-6B-448px-V1-5/
└──<span class="w"> </span>Nous-Hermes-2-Yi-34B/
</pre></div>
</div>
</section>
<section id="supervised-fine-tuning">
<h2>🔥 Supervised Fine-tuning<a class="headerlink" href="#supervised-fine-tuning" title="Permalink to this heading">#</a></h2>
<section id="prepare-training-datasets">
<h3>Prepare Training Datasets<a class="headerlink" href="#prepare-training-datasets" title="Permalink to this heading">#</a></h3>
<p>Inspired by LLaVA-NeXT, we adopted a data-efficient SFT strategy to train InternVL-Chat-V1-2, utilizing approximately 1.2M of visual instruction tuning samples in total, all of which are fully open-source. In a macro sense, we build upon <a class="reference external" href="https://github.com/InternLM/InternLM-XComposer/blob/main/projects/ShareGPT4V/docs/Data.md#prepare-images">ShareGPT-4V</a> and additionally integrate <a class="reference external" href="https://huggingface.co/datasets/openbmb/llava_zh">LLaVA-ZH</a>, <a class="reference external" href="https://github.com/kushalkafle/DVQA_dataset">DVQA</a>, <a class="reference external" href="https://github.com/vis-nlp/ChartQA">ChartQA</a>, <a class="reference external" href="https://allenai.org/data/diagrams">AI2D</a>, <a class="reference external" href="https://www.docvqa.org/datasets">DocVQA</a>, <a class="reference external" href="https://github.com/SCNU203/GeoQA-Plus">GeoQA+</a>, and <a class="reference external" href="https://huggingface.co/datasets/naver-clova-ix/synthdog-en">SynthDoG-EN</a>. Most of the data remains consistent with LLaVA-NeXT.</p>
<p>First, download the <a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL/resolve/main/playground.zip">annotation files</a> and place them in the <code class="docutils literal notranslate"><span class="pre">playground/opensource/</span></code> folder.</p>
<p>Second, download all the images we used.</p>
<ul class="simple">
<li><p>AI2D: <a class="reference external" href="https://drive.google.com/file/d/1dqqa3MnrxMXaU_K9JA6C83je32ibwdOY/view?usp=sharing">ai2d_images</a> (provided by InternLM-XComposer)</p></li>
<li><p>ChartQA: <a class="reference external" href="https://huggingface.co/datasets/ahmed-masry/ChartQA/resolve/main/ChartQA%20Dataset.zip">ChartQA Dataset</a></p></li>
<li><p>COCO: <a class="reference external" href="http://images.cocodataset.org/zips/train2017.zip">train2017</a></p></li>
<li><p>DocVQA: <a class="reference external" href="https://datasets.cvc.uab.es/rrc/DocVQA/train.tar.gz">train</a>, <a class="reference external" href="https://datasets.cvc.uab.es/rrc/DocVQA/val.tar.gz">val</a>, <a class="reference external" href="https://datasets.cvc.uab.es/rrc/DocVQA/test.tar.gz">test</a></p></li>
<li><p>DVQA: <a class="reference external" href="https://drive.google.com/file/d/1iKH2lTi1-QxtNUVRxTUWFvUvRHq6HAsZ/view">images</a></p></li>
<li><p>GQA: <a class="reference external" href="https://downloads.cs.stanford.edu/nlp/data/gqa/images.zip">images</a></p></li>
<li><p>LLaVA-Pretrain: <a class="reference external" href="https://huggingface.co/datasets/liuhaotian/LLaVA-Pretrain/resolve/main/images.zip">images</a></p></li>
<li><p>OCR-VQA: <a class="reference external" href="https://drive.google.com/drive/folders/1_GYPY5UkUy7HIcR0zq3ZCFgeZN7BAfm_?usp=sharing">download script</a>. We save all files as <code class="docutils literal notranslate"><span class="pre">.jpg</span></code></p></li>
<li><p>SAM: We only use 000000~000050.tar for now. You can quickly download 9K images from <a class="reference external" href="https://drive.google.com/file/d/1dKumdOKSXtV7lIXdrG7jsIK_z2vZv2gs/view?usp=drive_link">here</a>.</p></li>
<li><p>TextVQA: <a class="reference external" href="https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip">trainvalimages</a></p></li>
<li><p>SynthDoG-EN: We only use 00000~00004 parquet files for now, with a total of 30K images. We provide the converted <a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL/resolve/main/synthdog-en-images.zip">images</a>.</p></li>
<li><p>VisualGenome: <a class="reference external" href="https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip">part1</a>, <a class="reference external" href="https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip">part2</a></p></li>
<li><p>WebData: <a class="reference external" href="https://drive.google.com/drive/folders/1tCUQ-sq6vdshZVkF0ZeF3K4eztkXJgax?usp=sharing">images</a>. Only for academic usage.</p></li>
<li><p>GeoQA+: <a class="reference external" href="https://drive.google.com/file/d/1KL4_wIzr3p8XSKMkkLgYcYwCbb0TzZ9O/view">GeoQA+</a> <a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL/resolve/main/geoqa%2B_images.zip">images</a></p></li>
</ul>
<p>Then, organize the data as follows in <code class="docutils literal notranslate"><span class="pre">playground/data</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>playground/
├── opensource
│   ├── ai2d_train_12k.jsonl
│   ├── chartqa_train_18k.jsonl
│   ├── docvqa_train_10k.jsonl
│   ├── dvqa_train_200k.jsonl
│   ├── geoqa+.jsonl
│   ├── llava_instruct_150k_zh.jsonl
│   ├── sharegpt4v_instruct_gpt4-vision_cap100k.jsonl
│   ├── sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k.jsonl
│   └── synthdog_en.jsonl
├── data
│   ├── ai2d
│   │   ├── abc_images
│   │   └── images
│   ├── chartqa
│   │   ├── test
│   │   ├── train
│   │   └── val
│   ├── coco
│   │   └── train2017
│   ├── docvqa
│   │   ├── test
│   │   ├── train
│   │   └── val
│   ├── dvqa
│   │   └── images
│   ├── gqa
│   │   └── images
│   ├── llava
│   │   └── llava_pretrain
│   │       └── images
│   ├── ocr_vqa
│   │   └── images
│   ├── sam
│   │   └── images
│   ├── share_textvqa
│   │   └── images
│   ├── synthdog-en
│   │   └── images
│   ├── textvqa
│   │   └── train_images
│   ├── vg
│   │   ├── VG_100K
│   │   └── VG_100K_2
│   ├── web-celebrity
│   │   └── images
│   ├── web-landmark
│   │   └── images
│   ├── wikiart
│   │   └── images
│   ├── geoqa+
│   │   └── images
</pre></div>
</div>
</section>
<section id="start-training">
<h3>Start Training<a class="headerlink" href="#start-training" title="Permalink to this heading">#</a></h3>
<p>We provide slurm scripts for multi-node multi-GPU training. You can use either 32 or 64 GPUs to train this model. If you use 64 GPUs, training will take approximately 18 hours.</p>
<ul class="simple">
<li><p>If you encounter an OOM error, you can decrease the <code class="docutils literal notranslate"><span class="pre">PER_DEVICE_BATCH_SIZE</span></code>, for example, set <code class="docutils literal notranslate"><span class="pre">PER_DEVICE_BATCH_SIZE=4</span></code>.</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># using 32 GPUs</span>
<span class="nv">PARTITION</span><span class="o">=</span><span class="s1">&#39;your partition&#39;</span><span class="w"> </span><span class="nv">GPUS</span><span class="o">=</span><span class="m">32</span><span class="w"> </span><span class="nv">PER_DEVICE_BATCH_SIZE</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>shell/hermes2_yi34b/internvl_chat_v1_2_hermes2_yi34b_448_res_finetune.sh
<span class="c1"># using 64 GPUs</span>
<span class="nv">PARTITION</span><span class="o">=</span><span class="s1">&#39;your partition&#39;</span><span class="w"> </span><span class="nv">GPUS</span><span class="o">=</span><span class="m">64</span><span class="w"> </span><span class="nv">PER_DEVICE_BATCH_SIZE</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>shell/hermes2_yi34b/internvl_chat_v1_2_hermes2_yi34b_448_res_finetune.sh
</pre></div>
</div>
<p>The hyperparameters used for fine-tuning are listed in the following table. And, you can view the training logs in tensorboard at <a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2/tensorboard">here</a>.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Hyperparameter</p></th>
<th class="head"><p>Trainable Param</p></th>
<th class="head"><p>Global Batch Size</p></th>
<th class="head"><p>Learning rate</p></th>
<th class="head"><p>Epochs</p></th>
<th class="head"><p>Max length</p></th>
<th class="head"><p>Weight decay</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>InternVL-Chat-V1-2</p></td>
<td><p>40B (full model)</p></td>
<td><p>512</p></td>
<td><p>1e-5</p></td>
<td><p>1</p></td>
<td><p>2048</p></td>
<td><p>0.05</p></td>
</tr>
</tbody>
</table>
</section>
<section id="continued-fine-tune">
<h3>Continued Fine-tune<a class="headerlink" href="#continued-fine-tune" title="Permalink to this heading">#</a></h3>
<p>See <a class="reference internal" href="#../document/How_to_finetune_internvl_chat_v1_2_on_a_custom_dataset.md"><span class="xref myst">this document</span></a> to finetune InternVL-Chat-V1-2.</p>
</section>
</section>
<section id="evaluation">
<h2>📊 Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this heading">#</a></h2>
<p><strong>OCR-related Benchmarks</strong></p>
<p>Note: TextVQA contains two scores, representing not using or using Rosetta OCR tokens, respectively.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model</p></th>
<th class="head"><p>#param</p></th>
<th class="head"><p>DocVQA<br>(val/test)</p></th>
<th class="head"><p>ChartVQA<br>(avg. test)</p></th>
<th class="head"><p>InfoVQA<br>(val/test)</p></th>
<th class="head"><p>TextVQA<br>(val, wo/w OCR)</p></th>
<th class="head"><p>OCRBench</p></th>
<th class="head"><p>AI2D</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-1">InternVL‑Chat‑V1‑1</a></p></td>
<td><p>19B</p></td>
<td><p>47.6 / 48.1</p></td>
<td><p>59.9</p></td>
<td><p>33.3 / 32.0</p></td>
<td><p>64.2 / 68.6</p></td>
<td><p>530</p></td>
<td><p>72.4</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2">InternVL‑Chat‑V1‑2</a></p></td>
<td><p>40B</p></td>
<td><p>56.4 / 57.7</p></td>
<td><p>68.0</p></td>
<td><p>36.0 / 39.5</p></td>
<td><p>67.5 / 72.5</p></td>
<td><p>569</p></td>
<td><p>79.0</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2-Plus">InternVL‑Chat‑V1‑2‑Plus</a></p></td>
<td><p>40B</p></td>
<td><p>56.9 / 56.8</p></td>
<td><p>72.8</p></td>
<td><p>40.9 / 40.6</p></td>
<td><p>71.2 / 74.1</p></td>
<td><p>598</p></td>
<td><p>78.9</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5">InternVL‑Chat‑V1‑5</a></p></td>
<td><p>26B</p></td>
<td><p>90.5 / 90.8</p></td>
<td><p>83.8</p></td>
<td><p>72.4 / 72.5</p></td>
<td><p>80.6 / -</p></td>
<td><p>724</p></td>
<td><p>80.7</p></td>
</tr>
</tbody>
</table>
<p><strong>MultiModal Benchmark</strong></p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model</p></th>
<th class="head"><p>#param</p></th>
<th class="head"><p>MME</p></th>
<th class="head"><p>MMB<br>(dev/test)</p></th>
<th class="head"><p>MMB‑CN<br>(dev/test)</p></th>
<th class="head"><p>CCBench</p></th>
<th class="head"><p>MMVet</p></th>
<th class="head"><p>MMMU<br>(val/test)</p></th>
<th class="head"><p>MathVista<br>(testmini)</p></th>
<th class="head"><p>Hallusion<br>Bench</p></th>
<th class="head"><p>RealWorld<br/>QA</p></th>
<th class="head"><p>SEEDv1<br>(image)</p></th>
<th class="head"><p>CMMMU<br>(val/test)</p></th>
<th class="head"><p>POPE</p></th>
<th class="head"><p>MMVP</p></th>
<th class="head"><p>Tiny LVLM</p></th>
<th class="head"><p>LLaVA Wild</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-1">InternVL‑Chat‑V1‑1</a></p></td>
<td><p>19B</p></td>
<td><p>1659.8 / 361.4</p></td>
<td><p>76.7 / 75.4</p></td>
<td><p>71.9 / 70.3</p></td>
<td><p>43.3</p></td>
<td><p>46.7</p></td>
<td><p>39.1 / 35.3</p></td>
<td><p>34.5</p></td>
<td><p>36.1</p></td>
<td><p>58.0</p></td>
<td><p>73.2</p></td>
<td><p>34.8 / 34.0</p></td>
<td><p>87.1</p></td>
<td><p>44.7</p></td>
<td><p>343.2</p></td>
<td><p>73.2</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2">InternVL‑Chat‑V1‑2</a></p></td>
<td><p>40B</p></td>
<td><p>1686.8 / 488.6</p></td>
<td><p>81.4 / 82.2</p></td>
<td><p>79.5 / 81.2</p></td>
<td><p>58.6</p></td>
<td><p>48.9</p></td>
<td><p>51.6 / <a class="reference external" href="https://eval.ai/web/challenges/challenge-page/2179/leaderboard/5377">46.2</a></p></td>
<td><p>47.7</p></td>
<td><p>47.6</p></td>
<td><p>67.5</p></td>
<td><p>75.6</p></td>
<td><p>-</p></td>
<td><p>88.0</p></td>
<td><p>56.7</p></td>
<td><p>350.3</p></td>
<td><p>85.0</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2-Plus">InternVL‑Chat‑V1‑2‑Plus</a></p></td>
<td><p>40B</p></td>
<td><p>1625.2 / 552.9</p></td>
<td><p>83.4 / 83.8</p></td>
<td><p>81.6 / 82.0</p></td>
<td><p>55.9</p></td>
<td><p>47.9</p></td>
<td><p>50.3 / 45.6</p></td>
<td><p>59.9</p></td>
<td><p>47.4</p></td>
<td><p>67.8</p></td>
<td><p>76.4</p></td>
<td><p>-</p></td>
<td><p>88.7</p></td>
<td><p>58.7</p></td>
<td><p>353.9</p></td>
<td><p>84.6</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5">InternVL‑Chat‑V1‑5</a></p></td>
<td><p>26B</p></td>
<td><p>1637.8 / 550.0</p></td>
<td><p>- / 82.2</p></td>
<td><p>- / 82.0</p></td>
<td><p>70.0</p></td>
<td><p>62.8</p></td>
<td><p>45.2 / -</p></td>
<td><p>53.5</p></td>
<td><p>49.3</p></td>
<td><p>66.0</p></td>
<td><p>76.0</p></td>
<td><p>-</p></td>
<td><p>88.3</p></td>
<td><p>57.3</p></td>
<td><p>356.8</p></td>
<td><p>94.7</p></td>
</tr>
</tbody>
</table>
<p><strong>Visual Question Answering &amp; Image Captioning</strong></p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model</p></th>
<th class="head"><p>#param</p></th>
<th class="head"><p>OKVQA<br>(val)</p></th>
<th class="head"><p>VizWiz<br>(val/test)</p></th>
<th class="head"><p>GQA<br>(test)</p></th>
<th class="head"><p>SQA<br>(image)</p></th>
<th class="head"><p>VQAv2<br>(testdev)</p></th>
<th class="head"><p>COCO<br>(test)</p></th>
<th class="head"><p>Flickr30K<br>(test)</p></th>
<th class="head"><p>NoCaps<br>(val)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-1">InternVL‑Chat‑V1‑1</a></p></td>
<td><p>19B</p></td>
<td><p>64.1</p></td>
<td><p>59.0 / 57.3</p></td>
<td><p>62.5</p></td>
<td><p>90.1</p></td>
<td><p>80.9</p></td>
<td><p>142.2</p></td>
<td><p>84.8</p></td>
<td><p>120.8</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2">InternVL‑Chat‑V1‑2</a></p></td>
<td><p>40B</p></td>
<td><p>62.5</p></td>
<td><p>61.9 / 60.0</p></td>
<td><p>64.0</p></td>
<td><p>83.3</p></td>
<td><p>-</p></td>
<td><p>113.9</p></td>
<td><p>92.9</p></td>
<td><p>112.5</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2-Plus">InternVL‑Chat‑V1‑2‑Plus</a></p></td>
<td><p>40B</p></td>
<td><p>67.6</p></td>
<td><p>61.3 / 59.5</p></td>
<td><p>66.9</p></td>
<td><p>98.1</p></td>
<td><p>-</p></td>
<td><p>143.4</p></td>
<td><p>89.5</p></td>
<td><p>125.8</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5">InternVL‑Chat‑V1‑5</a></p></td>
<td><p>26B</p></td>
<td><p>62.0</p></td>
<td><p>63.5 / -</p></td>
<td><p>65.7</p></td>
<td><p>94.0</p></td>
<td><p>-</p></td>
<td><p>98.4</p></td>
<td><p>81.2</p></td>
<td><p>99.6</p></td>
</tr>
</tbody>
</table>
<p><strong>Visual Grounding</strong></p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model</p></th>
<th class="head"><p>#param</p></th>
<th class="head"><p>RefCOCO<br>(val)</p></th>
<th class="head"><p>RefCOCO<br>(testA)</p></th>
<th class="head"><p>RefCOCO<br>(testB)</p></th>
<th class="head"><p>RefCOCO+<br>(val)</p></th>
<th class="head"><p>RefCOCO+<br>(testA)</p></th>
<th class="head"><p>RefCOCO+<br>(testB)</p></th>
<th class="head"><p>RefCOCO‑g<br>(val)</p></th>
<th class="head"><p>RefCOCO‑g<br>(test)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-1">InternVL‑Chat‑V1‑1</a></p></td>
<td><p>19B</p></td>
<td><p>84.7</p></td>
<td><p>89.9</p></td>
<td><p>78.6</p></td>
<td><p>78.5</p></td>
<td><p>85.6</p></td>
<td><p>70.1</p></td>
<td><p>81.0</p></td>
<td><p>81.4</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2">InternVL‑Chat‑V1‑2</a></p></td>
<td><p>40B</p></td>
<td><p>74.4</p></td>
<td><p>80.3</p></td>
<td><p>66.5</p></td>
<td><p>70.7</p></td>
<td><p>77.6</p></td>
<td><p>62.0</p></td>
<td><p>69.2</p></td>
<td><p>70.0</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2-Plus">InternVL‑Chat‑V1‑2‑Plus</a></p></td>
<td><p>40B</p></td>
<td><p>90.2</p></td>
<td><p>93.4</p></td>
<td><p>85.5</p></td>
<td><p>85.3</p></td>
<td><p>90.4</p></td>
<td><p>79.7</p></td>
<td><p>88.5</p></td>
<td><p>88.8</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5">InternVL‑Chat‑V1‑5</a></p></td>
<td><p>26B</p></td>
<td><p>91.4</p></td>
<td><p>93.7</p></td>
<td><p>87.1</p></td>
<td><p>87.0</p></td>
<td><p>92.3</p></td>
<td><p>80.9</p></td>
<td><p>88.5</p></td>
<td><p>89.3</p></td>
</tr>
</tbody>
</table>
</section>
<section id="evaluation-legacy-models">
<h2>📊 Evaluation (Legacy Models)<a class="headerlink" href="#evaluation-legacy-models" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>model</p></th>
<th class="head"><p>QLLaMA</p></th>
<th class="head"><p>LLM</p></th>
<th class="head"><p>res</p></th>
<th class="head"><p>COCO</p></th>
<th class="head"><p>Flickr</p></th>
<th class="head"><p>NoCaps</p></th>
<th class="head"><p>VQAv2</p></th>
<th class="head"><p>GQA</p></th>
<th class="head"><p>VizWiz</p></th>
<th class="head"><p>TextVQA</p></th>
<th class="head"><p>MME</p></th>
<th class="head"><p>POPE</p></th>
<th class="head"><p>Download</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>InternVL‑Chat</p></td>
<td><p>✔️</p></td>
<td><p>frozen V‑7B</p></td>
<td><p>224</p></td>
<td><p>141.4</p></td>
<td><p>89.7</p></td>
<td><p>120.5</p></td>
<td><p>72.3</p></td>
<td><p>57.7</p></td>
<td><p>44.5</p></td>
<td><p>42.1</p></td>
<td><p>1298.5</p></td>
<td><p>85.2</p></td>
<td><p>TODO</p></td>
</tr>
<tr class="row-odd"><td><p>InternVL‑Chat</p></td>
<td><p>✔️</p></td>
<td><p>frozen V‑13B</p></td>
<td><p>224</p></td>
<td><p>142.4</p></td>
<td><p>89.9</p></td>
<td><p>123.1</p></td>
<td><p>71.7</p></td>
<td><p>59.5</p></td>
<td><p>54.0</p></td>
<td><p>49.1</p></td>
<td><p>1317.2</p></td>
<td><p>85.4</p></td>
<td><p>TODO</p></td>
</tr>
<tr class="row-even"><td><p>InternVL‑Chat</p></td>
<td><p>✔️</p></td>
<td><p>V‑13B</p></td>
<td><p>336</p></td>
<td><p>146.2</p></td>
<td><p>92.2</p></td>
<td><p>126.2</p></td>
<td><p>81.2</p></td>
<td><p>66.6</p></td>
<td><p>58.5</p></td>
<td><p>61.5</p></td>
<td><p>1586.4</p></td>
<td><p>87.6</p></td>
<td><p>TODO</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-evaluate">
<h2>❓ How to Evaluate<a class="headerlink" href="#how-to-evaluate" title="Permalink to this heading">#</a></h2>
<section id="image-caption-benchmarks">
<h3>Image Caption Benchmarks<a class="headerlink" href="#image-caption-benchmarks" title="Permalink to this heading">#</a></h3>
<section id="coco-karpathy-test">
<h4><a class="reference external" href="https://cocodataset.org/">COCO Karpathy test</a><a class="headerlink" href="#coco-karpathy-test" title="Permalink to this heading">#</a></h4>
<blockquote>
<div><p>COCO images are used in VQAv2/OK-VQA/RefCOCO/RefCOCO+/RefCOCOg. Make sure you have already downloaded COCO images before evaluating on these benchmarks.</p>
</div></blockquote>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/coco<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/coco

<span class="c1"># download coco images</span>
wget<span class="w"> </span>http://images.cocodataset.org/zips/train2014.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>train2014.zip
wget<span class="w"> </span>http://images.cocodataset.org/zips/val2014.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>val2014.zip
wget<span class="w"> </span>http://images.cocodataset.org/zips/test2015.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>test2015.zip

mkdir<span class="w"> </span>-p<span class="w"> </span>annotations<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>annotations/
<span class="c1"># download converted annotation files</span>
wget<span class="w"> </span>https://github.com/OpenGVLab/InternVL/releases/download/data/coco_karpathy_test.json
wget<span class="w"> </span>https://github.com/OpenGVLab/InternVL/releases/download/data/coco_karpathy_test_gt.json

<span class="nb">cd</span><span class="w"> </span>../../../
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>caption-coco<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="flickr30k-karpathy-test">
<h4><a class="reference external" href="https://bryanplummer.com/Flickr30kEntities/">Flickr30K Karpathy test</a><a class="headerlink" href="#flickr30k-karpathy-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/flickr30k<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/flickr30k

<span class="c1"># download images from https://bryanplummer.com/Flickr30kEntities/</span>
<span class="c1"># karpathy split annotations can be downloaded from the following link:</span>
<span class="c1"># https://github.com/mehdidc/retrieval_annotations/releases/download/1.0.0/flickr30k_test_karpathy.txt</span>
<span class="c1"># this file is provided by the clip-benchmark repository.</span>
<span class="c1"># We convert this txt file to json format, download the converted file:</span>
wget<span class="w"> </span>https://github.com/OpenGVLab/InternVL/releases/download/data/flickr30k_test_karpathy.json

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>caption-flickr30k<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="nocaps-val">
<h4><a class="reference external" href="https://nocaps.org/">NoCaps val</a><a class="headerlink" href="#nocaps-val" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/nocaps<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/nocaps

<span class="c1"># download images from https://nocaps.org/download</span>
<span class="c1"># original annotations can be downloaded from https://nocaps.s3.amazonaws.com/nocaps_val_4500_captions.json</span>
wget<span class="w"> </span>https://nocaps.s3.amazonaws.com/nocaps_val_4500_captions.json

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>caption-nocaps<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
</section>
<section id="general-vqa-benchmarks">
<h3>General VQA Benchmarks<a class="headerlink" href="#general-vqa-benchmarks" title="Permalink to this heading">#</a></h3>
<section id="vqav2-val-test-dev">
<h4><a class="reference external" href="https://visualqa.org/">VQAv2 val &amp; test-dev</a><a class="headerlink" href="#vqav2-val-test-dev" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/vqav2<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/vqav2

<span class="c1"># make sure you have downloaded COCO images</span>
ln<span class="w"> </span>-s<span class="w"> </span>../coco/train2014<span class="w"> </span>./
ln<span class="w"> </span>-s<span class="w"> </span>../coco/val2014<span class="w"> </span>./
ln<span class="w"> </span>-s<span class="w"> </span>../coco/test2015<span class="w"> </span>./

<span class="c1"># download questions and annotations</span>
wget<span class="w"> </span>https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>v2_Annotations_Train_mscoco.zip
wget<span class="w"> </span>https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>v2_Questions_Train_mscoco.zip
wget<span class="w"> </span>https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>v2_Annotations_Val_mscoco.zip
wget<span class="w"> </span>https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>v2_Questions_Val_mscoco.zip
wget<span class="w"> </span>https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Test_mscoco.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>v2_Questions_Test_mscoco.zip

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vqav2/vqav2_train.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vqav2/vqav2_val.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vqav2/vqav2_testdev.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># VQAv2-val</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-vqav2-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># VQAv2-testdev</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-vqav2-testdev<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
<p>For the testdev set, submit the results to the <a class="reference external" href="https://eval.ai/web/challenges/challenge-page/830/my-submission">evaluation server</a>.</p>
</details>
</section>
<section id="okvqa-val">
<h4><a class="reference external" href="https://okvqa.allenai.org/">OKVQA val</a><a class="headerlink" href="#okvqa-val" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/okvqa<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/okvqa

<span class="c1"># make sure you have downloaded COCO images</span>
ln<span class="w"> </span>-s<span class="w"> </span>../coco/train2014<span class="w"> </span>./
ln<span class="w"> </span>-s<span class="w"> </span>../coco/val2014<span class="w"> </span>./

<span class="c1"># download annotations and questions</span>
wget<span class="w"> </span>https://okvqa.allenai.org/static/data/mscoco_train2014_annotations.json.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>mscoco_train2014_annotations.json.zip
wget<span class="w"> </span>https://okvqa.allenai.org/static/data/OpenEnded_mscoco_train2014_questions.json.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>OpenEnded_mscoco_train2014_questions.json.zip
wget<span class="w"> </span>https://okvqa.allenai.org/static/data/mscoco_val2014_annotations.json.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>mscoco_val2014_annotations.json.zip
wget<span class="w"> </span>https://okvqa.allenai.org/static/data/OpenEnded_mscoco_val2014_questions.json.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>OpenEnded_mscoco_val2014_questions.json.zip

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/okvqa/okvqa_train.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/okvqa/okvqa_val.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-okvqa-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="textvqa-val">
<h4><a class="reference external" href="https://textvqa.org/">TextVQA val</a><a class="headerlink" href="#textvqa-val" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/textvqa<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/textvqa

<span class="c1"># download images</span>
wget<span class="w"> </span>https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>train_val_images.zip

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/textvqa/textvqa_train_annotations.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/textvqa/textvqa_train_questions.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/textvqa/textvqa_train.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/textvqa/textvqa_val_annotations.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/textvqa/textvqa_val_questions.json
wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/raw/main/textvqa_val.jsonl
wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/raw/main/textvqa_val_llava.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># without ocr tokens</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-textvqa-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># with ocr tokens (hint: LLaVA use ocr tokens)</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-textvqa-val-ocr<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="vizwiz-val-test">
<h4><a class="reference external" href="https://vizwiz.org/tasks-and-datasets/vqa/">VizWiz val &amp; test</a><a class="headerlink" href="#vizwiz-val-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/vizwiz<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/vizwiz

<span class="c1"># download images</span>
wget<span class="w"> </span>https://vizwiz.cs.colorado.edu/VizWiz_final/images/train.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>train.zip
wget<span class="w"> </span>https://vizwiz.cs.colorado.edu/VizWiz_final/images/val.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>val.zip
wget<span class="w"> </span>https://vizwiz.cs.colorado.edu/VizWiz_final/images/test.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>test.zip

<span class="c1"># download annotations</span>
wget<span class="w"> </span>https://vizwiz.cs.colorado.edu/VizWiz_final/vqa_data/Annotations.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>Annotations.zip

<span class="c1"># download converted files</span>
<span class="c1"># train</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_train_annotations.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_train_questions.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_train.jsonl
<span class="c1"># val</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_val_annotations.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_val_questions.json
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_val.jsonl
<span class="c1"># test</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/vizwiz/vizwiz_test.jsonl
<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># VizWiz val</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-vizwiz-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># VizWiz test</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-vizwiz-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
<p>For the test set, submit the results to the <a class="reference external" href="https://eval.ai/web/challenges/challenge-page/2185/overview">evaluation server</a>.</p>
</details>
</section>
<section id="docvqa-val-test">
<h4><a class="reference external" href="https://www.docvqa.org/datasets">DocVQA val &amp; test</a><a class="headerlink" href="#docvqa-val-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/docvqa<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/docvqa

<span class="c1"># download images and annotations</span>
wget<span class="w"> </span>https://datasets.cvc.uab.es/rrc/DocVQA/train.tar.gz<span class="w"> </span>--no-check-certificate<span class="w"> </span><span class="c1"># (optional)</span>
wget<span class="w"> </span>https://datasets.cvc.uab.es/rrc/DocVQA/val.tar.gz<span class="w"> </span>--no-check-certificate
wget<span class="w"> </span>https://datasets.cvc.uab.es/rrc/DocVQA/test.tar.gz<span class="w"> </span>--no-check-certificate

<span class="c1"># unzip files</span>
tar<span class="w"> </span>-zxvf<span class="w"> </span>train.tar.gz
tar<span class="w"> </span>-zxvf<span class="w"> </span>val.tar.gz
tar<span class="w"> </span>-zxvf<span class="w"> </span>test.tar.gz

<span class="c1"># download converted jsonl files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/docvqa/train.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/docvqa/val.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/docvqa/test.jsonl
<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># DocVQA-val</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-docvqa-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># DocVQA-test</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-docvqa-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
<p>For the test set, submit the results to the <a class="reference external" href="https://rrc.cvc.uab.es/?ch=17">evaluation server</a>.</p>
</details>
</section>
<section id="chartqa-test-human-test-augmented">
<h4><a class="reference external" href="https://aclanthology.org/2022.findings-acl.177/">ChartQA test-human &amp; test-augmented</a><a class="headerlink" href="#chartqa-test-human-test-augmented" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/chartqa<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/chartqa

<span class="c1"># download images from https://drive.google.com/file/d/1Lm_w6zeET1Hyl_9ks6w5nEsgpoyPHalV/view</span>

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/chartqa/train_human.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/chartqa/train_augmented.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/chartqa/test_human.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/chartqa/test_augmented.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># test both ChartQA-test-human &amp; ChartQA-test-augmented</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-chartqa-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="gqa-testdev">
<h4><a class="reference external" href="https://cs.stanford.edu/people/dorarad/gqa/about.html">GQA testdev</a><a class="headerlink" href="#gqa-testdev" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/gqa<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/gqa

<span class="c1"># download images</span>
wget<span class="w"> </span>https://downloads.cs.stanford.edu/nlp/data/gqa/images.zip
unzip<span class="w"> </span>images.zip

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/gqa/testdev_balanced.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/gqa/train_balanced.jsonl
wget<span class="w"> </span>https://github.com/OpenGVLab/InternVL/releases/download/data/llava_gqa_testdev_balanced_qwen_format.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-gqa-testdev<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="ocrvqa-val-test">
<h4><a class="reference external" href="https://ocr-vqa.github.io/">OCRVQA val &amp; test</a><a class="headerlink" href="#ocrvqa-val-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/ocrvqa<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/ocrvqa

<span class="c1"># download images by following instructions at https://ocr-vqa.github.io/kvqa_ProjectFiles/README.txt</span>

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/ocrvqa/ocrvqa_train.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/ocrvqa/ocrvqa_val.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/ocrvqa/ocrvqa_test.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># OCRVQA-val</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-ocrvqa-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># OCRVQA-test</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-ocrvqa-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="ai2d-test">
<h4><a class="reference external" href="https://allenai.org/data/diagrams">AI2D test</a><a class="headerlink" href="#ai2d-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/ai2diagram<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/ai2diagram
<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/raw/main/ai2d_test_vlmevalkit.jsonl<span class="w"> </span>-O<span class="w"> </span>test_vlmevalkit.jsonl
wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/resolve/main/AI2D_TEST.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>AI2D_TEST.zip

<span class="c1"># download images from Google drive (optional, provided by InternLM-XComposer)</span>
<span class="c1"># https://drive.google.com/file/d/1dqqa3MnrxMXaU_K9JA6C83je32ibwdOY/view?usp=sharing</span>
<span class="c1"># images should be placed in `data/ai2diagram/ai2d/abc_images` and `data/ai2diagram/ai2d/images`</span>
<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>vqa-ai2d-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="scienceqa-test">
<h4><a class="reference external" href="https://github.com/lupantech/ScienceQA">ScienceQA test</a><a class="headerlink" href="#scienceqa-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/scienceqa/images<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/scienceqa/images

<span class="c1"># download images</span>
wget<span class="w"> </span>https://scienceqa.s3.us-west-1.amazonaws.com/images/test.zip<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>unzip<span class="w"> </span>test.zip

<span class="nb">cd</span><span class="w"> </span>..

<span class="c1"># download original questions</span>
wget<span class="w"> </span>https://github.com/lupantech/ScienceQA/blob/main/data/scienceqa/problems.json

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/scienceqa/scienceqa_test_img.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>scienceqa<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
</section>
<section id="refer-expression-comprehension">
<h3>Refer Expression Comprehension<a class="headerlink" href="#refer-expression-comprehension" title="Permalink to this heading">#</a></h3>
<section id="refcoco-refcoco-refcoco-g">
<h4>RefCOCO/RefCOCO+/RefCOCO-g<a class="headerlink" href="#refcoco-refcoco-refcoco-g" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/refcoco<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/refcoco

<span class="c1"># download converted files</span>
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcoco/refcoco_val.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcoco/refcoco_testA.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcoco/refcoco_testB.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcoco%2B/refcoco%2B_val.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcoco%2B/refcoco%2B_testA.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcoco%2B/refcoco%2B_testB.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcocog/refcocog_val.jsonl
wget<span class="w"> </span>https://ofasys-wlcb.oss-cn-wulanchabu.aliyuncs.com/Qwen-VL/evaluation/refcocog/refcocog_test.jsonl

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>refcoco<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
</section>
<section id="multimodal-benchmarks">
<h3>MultiModal Benchmarks<a class="headerlink" href="#multimodal-benchmarks" title="Permalink to this heading">#</a></h3>
<section id="mme">
<h4><a class="reference external" href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation">MME</a><a class="headerlink" href="#mme" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/mme<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/mme

<span class="c1"># 1. Download the data following the official instructions [here](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation).</span>
<span class="c1"># 2. Downloaded images to `MME_Benchmark_release_version`.</span>

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># single GPU testing</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mme
</pre></div>
</div>
</details>
</section>
<section id="mmbench-dev-test">
<h4><a class="reference external" href="https://github.com/open-compass/mmbench/?tab=readme-ov-file">MMBench dev &amp; test</a><a class="headerlink" href="#mmbench-dev-test" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/mmbench<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/mmbench

<span class="c1"># download csv files of mmbench</span>
wget<span class="w"> </span>http://opencompass.openxlab.space/utils/MMBench/CCBench_legacy.tsv
wget<span class="w"> </span>https://download.openmmlab.com/mmclassification/datasets/mmbench/mmbench_dev_20230712.tsv
wget<span class="w"> </span>https://download.openmmlab.com/mmclassification/datasets/mmbench/mmbench_dev_cn_20231003.tsv
wget<span class="w"> </span>https://download.openmmlab.com/mmclassification/datasets/mmbench/mmbench_dev_en_20231003.tsv
wget<span class="w"> </span>https://download.openmmlab.com/mmclassification/datasets/mmbench/mmbench_test_cn_20231003.tsv
wget<span class="w"> </span>https://download.openmmlab.com/mmclassification/datasets/mmbench/mmbench_test_en_20231003.tsv

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># mmbench_dev_20230712</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmbench-dev-en<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># mmbench_dev_cn_20231003</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmbench-dev-cn<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># mmbench_test_en_20231003</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmbench-test-en<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># mmbench_test_cn_20231003</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmbench-test-cn<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># ccbench_dev</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>ccbench-dev<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
<p>Then, submit the results to the <a class="reference external" href="https://mmbench.opencompass.org.cn/mmbench-submission">evaluation server</a>.</p>
</details>
</section>
<section id="pope">
<h4><a class="reference external" href="https://github.com/AoiDragon/POPE/tree/main">POPE</a><a class="headerlink" href="#pope" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/pope<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/pope

<span class="c1"># make sure you have downloaded COCO images</span>
ln<span class="w"> </span>-s<span class="w"> </span>../coco/val2014<span class="w"> </span>./
wget<span class="w"> </span>https://github.com/OpenGVLab/InternVL/releases/download/data/llava_pope_test.jsonl

<span class="c1"># download `coco` from POPE</span>
mkdir<span class="w"> </span>-p<span class="w"> </span>coco<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>coco
wget<span class="w"> </span>https://github.com/AoiDragon/POPE/raw/e3e39262c85a6a83f26cf5094022a782cb0df58d/output/coco/coco_pope_adversarial.json
wget<span class="w"> </span>https://github.com/AoiDragon/POPE/raw/e3e39262c85a6a83f26cf5094022a782cb0df58d/output/coco/coco_pope_popular.json
wget<span class="w"> </span>https://github.com/AoiDragon/POPE/raw/e3e39262c85a6a83f26cf5094022a782cb0df58d/output/coco/coco_pope_random.json
<span class="nb">cd</span><span class="w"> </span>../../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>pope<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="mmmu">
<h4><a class="reference internal" href="#MMMU_validation_240124181104.json"><span class="xref myst">MMMU</span></a><a class="headerlink" href="#mmmu" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<p>The evaluation code will automatically download the dataset from hugging face.</p>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># dev set</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmmu-dev<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># val set</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmmu-val<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># test set</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmmu-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
<p>For the test set, submit the results to the <a class="reference external" href="https://eval.ai/web/challenges/challenge-page/2179/overview">evaluation server</a>.</p>
</details>
</section>
<section id="tiny-lvlm">
<h4><a class="reference external" href="https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation">Tiny LVLM</a><a class="headerlink" href="#tiny-lvlm" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/tiny_lvlm<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/tiny_lvlm

<span class="c1"># download dataset from https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation</span>
<span class="c1"># i.e., download `updated_datasets.tar.gz` from https://drive.google.com/file/d/1PuFC612XzOmKwzRldtBb1CFZnIjiR7we/view</span>
tar<span class="w"> </span>-xzvf<span class="w"> </span>updated_datasets.tar.gz

<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>tiny_lvlm<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="llava-bench">
<h4><a class="reference external" href="https://huggingface.co/datasets/liuhaotian/llava-bench-in-the-wild">LLaVA Bench</a><a class="headerlink" href="#llava-bench" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>data/
<span class="c1"># download dataset from https://huggingface.co/datasets/liuhaotian/llava-bench-in-the-wild</span>
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/datasets/liuhaotian/llava-bench-in-the-wild
<span class="nb">cd</span><span class="w"> </span>llava-bench-in-the-wild/
rm<span class="w"> </span>-rf<span class="w"> </span>images<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>images<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>images
<span class="c1"># download all 24 images</span>
wget<span class="w"> </span>https://huggingface.co/datasets/liuhaotian/llava-bench-in-the-wild/resolve/main/images/001.jpg
<span class="c1"># ...</span>
wget<span class="w"> </span>https://huggingface.co/datasets/liuhaotian/llava-bench-in-the-wild/resolve/main/images/024.jpg
<span class="nb">cd</span><span class="w"> </span>../../../
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># single GPU testing</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span><span class="s1">&#39;your_gpt4_key&#39;</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>llava-bench
</pre></div>
</div>
</details>
</section>
<section id="mm-vet">
<h4><a class="reference external" href="https://github.com/yuweihao/MM-Vet?tab=readme-ov-file">MM-Vet</a><a class="headerlink" href="#mm-vet" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/mm-vet<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/mm-vet
wget<span class="w"> </span>https://github.com/yuweihao/MM-Vet/releases/download/v1/mm-vet.zip
unzip<span class="w"> </span>mm-vet.zip
wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/raw/main/llava-mm-vet.jsonl
<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmvet<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="mmvp">
<h4><a class="reference external" href="https://github.com/tsb0601/MMVP">MMVP</a><a class="headerlink" href="#mmvp" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>data
git<span class="w"> </span>lfs<span class="w"> </span>install
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/datasets/MMVP/MMVP
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/datasets/MMVP/MMVP_VLM
<span class="nb">cd</span><span class="w"> </span>..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mmvp<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="mathvista">
<h4><a class="reference external" href="https://github.com/lupantech/MathVista">MathVista</a><a class="headerlink" href="#mathvista" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/MathVista<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/MathVista
wget<span class="w"> </span>https://huggingface.co/datasets/AI4Math/MathVista/raw/main/annot_testmini.json
<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span><span class="s1">&#39;your-openai-key&#39;</span>
<span class="c1"># testmini set</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mathvista-testmini<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
<span class="c1"># test set</span>
<span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>mathvista-test<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
<section id="seed">
<h4><a class="reference external" href="https://github.com/AILab-CVC/SEED-Bench/">SEED</a><a class="headerlink" href="#seed" title="Permalink to this heading">#</a></h4>
<details>
<summary>Data Preparation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>data/SEED<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>data/SEED
<span class="c1"># 1. Follow the official instructions [Data Preparation for SEED-Bench-1](https://github.com/AILab-CVC/SEED-Bench/blob/main/DATASET.md#data-preparation-for-seed-bench-1)</span>
<span class="c1">#    to download the images and the videos. Put images under `./data/SEED/SEED-Bench-image`.</span>
<span class="c1"># 2. Extract the video frame in the middle from the downloaded videos, and put them under `./data/SEED/SEED-Bench-image`.</span>
<span class="c1">#    LLaVA provided the script [`extract_video_frames.py`](../internvl_chat/tools/extract_video_frames.py) modified from the official one.</span>

wget<span class="w"> </span>https://huggingface.co/OpenGVLab/InternVL/raw/main/seed.jsonl
<span class="nb">cd</span><span class="w"> </span>../..
</pre></div>
</div>
</details>
<details>
<summary>Evaluation</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">8</span><span class="w"> </span>sh<span class="w"> </span>evaluate.sh<span class="w"> </span>&lt;checkpoint&gt;<span class="w"> </span>seed<span class="w"> </span><span class="o">[</span>--dynamic<span class="o">]</span>
</pre></div>
</div>
</details>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installation">🛠️ Installation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-preparation">📦 Model Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">🔥 Supervised Fine-tuning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-datasets">Prepare Training Datasets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-training">Start Training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continued-fine-tune">Continued Fine-tune</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">📊 Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-legacy-models">📊 Evaluation (Legacy Models)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-evaluate">❓ How to Evaluate</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-caption-benchmarks">Image Caption Benchmarks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coco-karpathy-test">COCO Karpathy test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#flickr30k-karpathy-test">Flickr30K Karpathy test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#nocaps-val">NoCaps val</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-vqa-benchmarks">General VQA Benchmarks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vqav2-val-test-dev">VQAv2 val &amp; test-dev</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#okvqa-val">OKVQA val</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#textvqa-val">TextVQA val</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vizwiz-val-test">VizWiz val &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#docvqa-val-test">DocVQA val &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#chartqa-test-human-test-augmented">ChartQA test-human &amp; test-augmented</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gqa-testdev">GQA testdev</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ocrvqa-val-test">OCRVQA val &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ai2d-test">AI2D test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scienceqa-test">ScienceQA test</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#refer-expression-comprehension">Refer Expression Comprehension</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#refcoco-refcoco-refcoco-g">RefCOCO/RefCOCO+/RefCOCO-g</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-benchmarks">MultiModal Benchmarks</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mme">MME</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mmbench-dev-test">MMBench dev &amp; test</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pope">POPE</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mmmu"><span class="xref myst">MMMU</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-lvlm">Tiny LVLM</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#llava-bench">LLaVA Bench</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mm-vet">MM-Vet</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mmvp">MMVP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mathvista">MathVista</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#seed">SEED</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By InternVL Authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, OpenGVLab.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Jul 25, 2024.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>